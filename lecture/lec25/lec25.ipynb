{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 25 â€“ Data 100, Spring 2024\n",
    "\n",
    "Data 100, Spring 2024\n",
    "\n",
    "[Acknowledgments Page](https://ds100.org/sp24/acks/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "from ds100_utils import *\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA with SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rectangle = pd.read_csv(\"data/rectangle_data.csv\")\n",
    "rectangle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Center the Data Matrix $X$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = rectangle - np.mean(rectangle, axis = 0)\n",
    "X.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some situations where the units are on different scales it is useful to normalize the data before performing SVD. \n",
    "This can be done by dividing each column by its standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X / np.std(X, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Get the SVD of centered $X$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, S, Vt = np.linalg.svd(X, full_matrices = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of U\", U.shape)\n",
    "print(\"Shape of S\", S.shape)\n",
    "print(\"Shape of Vt\", Vt.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$S$ is a little different in `NumPy`. Since the only useful values in the diagonal matrix $S$ are the singular values on the diagonal axis, only those values are returned and they are stored in an array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want the diagonal elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sm = np.diag(S)\n",
    "Sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, looks like are four diagonal entries are not zero. What happened?\n",
    "\n",
    "It turns out there were some numerical rounding errors, but the last value is so small ($10^{-15}$) that it's practically $0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isclose(S[3], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S.round(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.round(np.diag(S),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the contribution to the total variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.round(S**2 / X.shape[0], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see that most of the variance is in the first two dimensions which makes sense since rectangles are largely described by two numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 Computing Approximations to the Data\n",
    "\n",
    "Let's try to approximate this data in two dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using $Z = U * S$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = U[:, :2] @ np.diag(S[:2])\n",
    "pd.DataFrame(Z).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using $Z = X * V$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = X.to_numpy() @ Vt.T[:,:2]\n",
    "pd.DataFrame(Z).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(x=Z[:, 0], y=Z[:, 1], render_mode=\"svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing to scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(2)\n",
    "pd.DataFrame(pca.fit_transform(X)).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(Z).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(pca.fit_transform(X)).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also notice that the covariance of the transformed diagonalized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.cov(Z.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lower Rank Approximation of X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now try to recover X from our approximation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rectangle.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 2\n",
    "U, S, Vt = np.linalg.svd(X, full_matrices = False)\n",
    "\n",
    "## Construct the latent factors\n",
    "Z = U[:,:k] @ np.diag(S[:k])\n",
    "\n",
    "## Reconstruct the original rectangle using the factors Z and the principle components\n",
    "rectangle_hat = pd.DataFrame(Z @ Vt[:k, :], columns = rectangle.columns)\n",
    "\n",
    "## Scale and shift the factors back to the original coordinate system\n",
    "rectangle_hat = rectangle_hat * np.std(rectangle, axis = 0) + np.mean(rectangle, axis = 0)\n",
    "\n",
    "\n",
    "## Plot the data\n",
    "fig = px.scatter_3d(rectangle, x=\"width\", y=\"height\", z=\"area\",\n",
    "                    width=800, height=600)\n",
    "fig.add_scatter3d(x=rectangle_hat[\"width\"], \n",
    "                  y=rectangle_hat[\"height\"], \n",
    "                  z=rectangle_hat[\"area\"], \n",
    "                  mode=\"markers\", name = \"approximation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>\n",
    "</br>\n",
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> <br>\n",
    "**Return to Lecture**\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congressional Vote Records\n",
    "\n",
    "Let's examine how the House of Representatives (of the 116th Congress, 1st session) voted in the month of **September 2019**.\n",
    "\n",
    "From the [U.S. Senate website](https://www.senate.gov/reference/Index/Votes.htm):\n",
    "\n",
    "> Roll call votes occur when a representative or senator votes \"yea\" or \"nay,\" so that the names of members voting on each side are recorded. A voice vote is a vote in which those in favor or against a measure say \"yea\" or \"nay,\" respectively, without the names or tallies of members voting on each side being recorded.\n",
    "\n",
    "The data, compiled from ProPublica [source](https://github.com/eyeseast/propublica-congress), is a \"skinny\" table of data where each record is a single vote by a member across any roll call in the 116th Congress, 1st session, as downloaded in February 2020. The member of the House, whom we'll call **legislator**, is denoted by their bioguide alphanumeric ID in http://bioguide.congress.gov/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# February 2019 House of Representatives roll call votes\n",
    "# Downloaded using https://github.com/eyeseast/propublica-congress\n",
    "votes = pd.read_csv('data/votes.csv')\n",
    "votes = votes.astype({\"roll call\": str}) \n",
    "votes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we pivot this table to group each legislator and their voting pattern across every (roll call) vote in this month. We mark 1 if the legislator voted Yes (yea), and 0 otherwise (No/nay, no vote, speaker, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def was_yes(s):\n",
    "    return 1 if s.iloc[0] == \"Yes\" else 0    \n",
    "vote_pivot = votes.pivot_table(index='member', \n",
    "                                columns='roll call', \n",
    "                                values='vote', \n",
    "                                aggfunc=was_yes, \n",
    "                                fill_value=0)\n",
    "print(vote_pivot.shape)\n",
    "vote_pivot.head()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we analyze this data?\n",
    "\n",
    "While we could consider loading information about the legislator, such as their party, and see how this relates to their voting pattern, it turns out that we can do a lot with PCA to cluster legislators by how they vote."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_pivot_centered = vote_pivot - np.mean(vote_pivot, axis = 0)\n",
    "vote_pivot_centered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/><br/><br/><br/>\n",
    "\n",
    "SLIDO QUESTION\n",
    "\n",
    "<br/><br/><br/><br/><br/><br/><br/><br/><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_pivot_centered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, s, vt = np.linalg.svd(vote_pivot_centered, full_matrices = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"u.shape\", u.shape)\n",
    "print(\"s.shape\", s.shape)\n",
    "print(\"vt.shape\", vt.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_2d = pd.DataFrame(index = vote_pivot_centered.index)\n",
    "vote_2d[[\"z1\", \"z2\", \"z3\"]] = (u * s)[:, :3]\n",
    "px.scatter(vote_2d, x='z1', y='z2', title='Vote Data', width=800, height=600, render_mode=\"svg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be interesting to see the political affiliation for each vote."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Component Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the first two singular values are large and all others are small, then two dimensions are enough to describe most of what distinguishes one observation from another. If not, then a PCA scatter plot is omitting lots of information.\n",
    "\n",
    "An equivalent way to evaluate this is to determine the **variance ratios**, i.e., the fraction of the variance each PC contributes to total variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/>\n",
    "\n",
    "SLIDO QUESTION\n",
    "\n",
    "<br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(s**2 / sum(s**2), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scree plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **scree plot** (and where its \"elbow\" is located) is a visual way of checking the distribution of variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(y=s**2 / sum(s**2), title='Variance Explained', width=700, height=400, markers=True)\n",
    "fig.update_xaxes(title_text='Principal Component')\n",
    "fig.update_yaxes(title_text='Proportion of Variance Explained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(vote_2d, x='z1', y='z2', z='z3', title='Vote Data', width=800, height=600)\n",
    "fig.update_traces(marker=dict(size=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baesd on the plot above, it looks like there are two clusters of datapoints. What do you think this corresponds to?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incorporating Member Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we load in more member information, from https://github.com/unitedstates/congress-legislators. This includes each legislator's political party."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can get current information about legislators with this code. In our case, we'll use\n",
    "# a static copy of the 2019 membership roster to properly match our voting data.\n",
    "\n",
    "# base_url = 'https://raw.githubusercontent.com/unitedstates/congress-legislators/main/'\n",
    "# legislators_path = 'legislators-current.yaml'\n",
    "# f = fetch_and_cache(base_url + legislators_path, legislators_path)\n",
    "\n",
    "# Use 2019 data copy\n",
    "legislators_data = yaml.safe_load(open('data/legislators-2019.yaml'))\n",
    "\n",
    "def to_date(s):\n",
    "    return datetime.strptime(s, '%Y-%m-%d')\n",
    "\n",
    "legs = pd.DataFrame(\n",
    "    columns=['leg_id', 'first', 'last', 'gender', 'state', 'chamber', 'party', 'birthday'],\n",
    "    data=[[x['id']['bioguide'], \n",
    "           x['name']['first'],\n",
    "           x['name']['last'],\n",
    "           x['bio']['gender'],\n",
    "           x['terms'][-1]['state'],\n",
    "           x['terms'][-1]['type'],\n",
    "           x['terms'][-1]['party'],\n",
    "           to_date(x['bio']['birthday'])] for x in legislators_data])\n",
    "legs['age'] = 2024 - legs['birthday'].dt.year\n",
    "legs.set_index(\"leg_id\")\n",
    "legs.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine the vote data projected onto the principal components with the biographic data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_2d = vote_2d.join(legs.set_index('leg_id')).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can visualize this data all at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(vote_2d, x='z1', y='z2', color='party', symbol=\"gender\", size='age',\n",
    "           title='Vote Data', width=800, height=600, size_max=10,\n",
    "           opacity = 0.7,\n",
    "           color_discrete_map={'Democrat':'blue', 'Republican':'red', \"Independent\": \"green\"},\n",
    "           hover_data=['first', 'last', 'state', 'party', 'gender', 'age'],\n",
    "           render_mode=\"svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be a bunch of overplotting, so let's jitter a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "vote_2d['z1_jittered'] = vote_2d['z1'] + np.random.normal(0, 0.1, len(vote_2d))\n",
    "vote_2d['z2_jittered'] = vote_2d['z2'] + np.random.normal(0, 0.1, len(vote_2d))\n",
    "vote_2d['z3_jittered'] = vote_2d['z3'] + np.random.normal(0, 0.1, len(vote_2d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(vote_2d, x='z1_jittered', y='z2_jittered', color='party', symbol=\"gender\", size='age',\n",
    "           title='Vote Data', width=800, height=600, size_max=10,\n",
    "           opacity = 0.7,\n",
    "           color_discrete_map={'Democrat':'blue', 'Republican':'red', \"Independent\": \"green\"},\n",
    "           hover_data=['first', 'last', 'state', 'party', 'gender', 'age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter_3d(\n",
    "    vote_2d, x='z1_jittered', y='z2_jittered', z='z3_jittered', \n",
    "    color='party', symbol=\"gender\", size='age',\n",
    "    title='Vote Data', width=800, height=600, size_max=10,\n",
    "    opacity = 0.7,\n",
    "    color_discrete_map={'Democrat':'blue', 'Republican':'red', \"Independent\": \"green\"},\n",
    "    hover_data=['first', 'last', 'state', 'party', 'gender', 'age']\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Analysis: Regular Voters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not everyone voted all the time.  Let's examine the frequency of voting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's recompute the pivot table where we only consider Yes/No votes, and ignore records with \"No Vote\" or other entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_2d[\"num votes\"] = (\n",
    "    votes[votes[\"vote\"].isin([\"Yes\", \"No\"])]\n",
    "        .groupby(\"member\").size()\n",
    ")\n",
    "vote_2d.dropna(inplace=True)\n",
    "vote_2d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram with a jittered marginal\n",
    "px.histogram(vote_2d, x=\"num votes\", log_x=True, width=800, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(vote_2d, x='z1_jittered', y='z2_jittered', color='party', symbol=\"gender\", size='num votes',\n",
    "           title='Vote Data (Size is Number of Votes)', width=800, height=600, size_max=10,\n",
    "           opacity = 0.7,\n",
    "           color_discrete_map={'Democrat':'blue', 'Republican':'red', \"Independent\": \"green\"},\n",
    "           hover_data=['first', 'last', 'state', 'party', 'gender', 'age'], \n",
    "           render_mode=\"svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Principal Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at Vt directly to try to gain insight into why each component is as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_eig = px.bar(x=vote_pivot_centered.columns, y=vt[0,:])\n",
    "# extract the trace from the figure\n",
    "fig_eig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the party affiliation labels so we can see if this eigenvector aligns with one of the parties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_line_votes = (\n",
    "    vote_pivot_centered.join(legs.set_index(\"leg_id\")['party'])\n",
    "                       .groupby(\"party\").mean()\n",
    "                       .T.reset_index()\n",
    "                       .rename(columns={\"index\": \"call\"})\n",
    "                       .melt(\"call\")\n",
    ")\n",
    "fig = px.bar(\n",
    "    party_line_votes,\n",
    "    x=\"call\", y=\"value\", facet_row = \"party\", color=\"party\",\n",
    "    color_discrete_map={'Democrat':'blue', 'Republican':'red', \"Independent\": \"green\"})\n",
    "fig.for_each_annotation(lambda a: a.update(text=a.text.split(\"=\")[-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_eig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings = pd.DataFrame(\n",
    "    {\n",
    "    \"pc1\": np.sqrt(s[0]) * vt[0,:], \n",
    "    \"pc2\": np.sqrt(s[1]) * vt[1,:]\n",
    "    }, \n",
    "    index=vote_pivot_centered.columns)   \n",
    "loadings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    vote_2d, x='z1_jittered', y='z2_jittered', color='party', symbol=\"gender\", size='num votes',\n",
    "    title='Biplot', width=800, height=600, size_max=10,\n",
    "    opacity = 0.7,\n",
    "    color_discrete_map={'Democrat':'blue', 'Republican':'red', \"Independent\": \"green\"},\n",
    "    hover_data=['first', 'last', 'state', 'party', 'gender', 'age'],\n",
    "    render_mode=\"svg\")\n",
    "\n",
    "for (call, pc1, pc2) in loadings.head(50).itertuples():\n",
    "    fig.add_scatter(x=[0,pc1], y=[0,pc2], name=call, \n",
    "                    mode='lines+markers', textposition='top right',\n",
    "                    marker= dict(size=10,symbol= \"arrow-bar-up\", angleref=\"previous\"))\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each roll call from the 116th Congress - 1st Session: https://clerk.house.gov/evs/2019/ROLL_500.asp\n",
    "* 555: Raising a question of the privileges of the House ([H.Res.590](https://www.congress.gov/bill/116th-congress/house-resolution/590))\n",
    "* 553: [https://www.congress.gov/bill/116th-congress/senate-joint-resolution/54/actions]\n",
    "* 527: On Agreeing to the Amendment [H.R.1146 - Arctic Cultural and Coastal Plain Protection Act](https://www.congress.gov/bill/116th-congress/house-bill/1146)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion-MNIST dataset\n",
    "\n",
    "We will be using the Fashion-MNIST dataset, which is a cool little dataset with gray scale 28x28 images of articles of clothing.\n",
    "\n",
    "Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms. Han Xiao, Kashif Rasul, Roland Vollgraf. arXiv:1708.07747\n",
    "https://github.com/zalandoresearch/fashion-mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "print(\"Training images\", train_images.shape)\n",
    "print(\"Test images\", test_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class names for this data are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "class_dict = {i:class_name for i, class_name in enumerate(class_names)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have loaded a lot of data which you can play with later (try building a classifier). \n",
    "\n",
    "For the purposes of this demo, let's take a small sample of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "n = 5000\n",
    "sample_idx = rng.choice(np.arange(len(train_images)), size=n, replace=False)\n",
    "\n",
    "# Invert and normalize the images so they look better\n",
    "img_mat = -1. * train_images[sample_idx]\n",
    "img_mat = (img_mat - img_mat.min())/(img_mat.max() - img_mat.min())\n",
    "\n",
    "images = pd.DataFrame({\"images\": img_mat.tolist(), \n",
    "                   \"labels\": train_labels[sample_idx], \n",
    "                   \"class\": [class_dict[x] for x in train_labels[sample_idx]]})\n",
    "images.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following snippet of code visualizes the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images, ncols=5, max_images=30):\n",
    "    # conver the subset of images into a n,28,28 matrix for facet visualization\n",
    "    img_mat = np.array(images.head(max_images)['images'].to_list())\n",
    "    fig = px.imshow(img_mat, color_continuous_scale='gray', \n",
    "                    facet_col = 0, facet_col_wrap=ncols,\n",
    "                    height = 220*int(np.ceil(len(images)/ncols)))\n",
    "    fig.update_layout(coloraxis_showscale=False)\n",
    "    # Extract the facet number and convert it back to the class label.\n",
    "    fig.for_each_annotation(lambda a: a.update(text=images.iloc[int(a.text.split(\"=\")[-1])]['class']))\n",
    "    return fig\n",
    "\n",
    "show_images(images.head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(images.groupby('class',as_index=False).sample(2), ncols=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n",
    "\n",
    "How would we visualize the entire dataset?  Let's use PCA to find a low dimensional representation of the images. \n",
    "\n",
    "First, let's understand the high-dimensional representation. We will extract the matrix of images from the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(images['images'].to_list())\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now \"unroll\" the pixels into a single row vector 28*28 = 784 dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(X.shape[0], -1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Center the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X - X.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run PCA (this time we use SKLearn):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "n_comps = 50 \n",
    "pca = PCA(n_components=n_comps)\n",
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining PCA Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a line plot and show markers\n",
    "px.line(y=pca.explained_variance_ratio_ *100, markers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of data is explained in first two or three dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images[['z1', 'z2', 'z3']] = pca.transform(X)[:, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(images, x='z1', y='z2', hover_data=['labels'], opacity=0.7,\n",
    "           width = 800, height = 600, render_mode=\"svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(images, x='z1', y='z2', color='class', hover_data=['labels'], opacity=0.7, \n",
    "           width = 800, height = 600, render_mode=\"svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(images, x='z1', y='z2', z='z3', color='class', hover_data=['labels'], \n",
    "                    width=1000, height=600)\n",
    "# set marker size to 5\n",
    "fig.update_traces(marker=dict(size=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
